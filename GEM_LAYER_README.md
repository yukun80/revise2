# HAEF-Net 当前实现状态与可训练性说明

## 概述
已在 HARMF 基础上实现 2D 版 GEM-Layer 并完成 HAEF-Net（层次化注意 + 证据融合）集成：编码器多尺度特征经 1×1 统一到 256 通道后进入 GEM，输出多尺度质量函数，插值到统一分辨率并经轻量决策头得到最终分割；同时提供不确定性图（Theta质量）。

## 实现完成度
- 2D GEM-Layer（完全可微）：`[B, C, H, W] → [B, K+1, H, W]`，含不确定性通道。
- 多尺度集成与对齐：各 stage 证据图统一插值后融合。
- 决策级输出：拼接 `(K+1)×num_stages` 通道 → 轻量卷积头 → `[B, K, H, W]`。
- 不确定性导出：提供 `get_uncertainty_map`。
- 工程集成：`model.type: haefnet`，与原训练流程兼容。

## 测试结论（multimodal 环境）
- GEM-Layer单测：通过（质量函数和=1，概率归一化正确）。
- HAEF-Net前向：通过（输出主干分割与证据分割，形状正确）。
- 训练兼容性：通过（可计算损失并反向传播，示例损失 ~0.70）。

## 是否可训练
- 结论：可以，训练就绪。
- 建议命令：
  - `python train.py --config configs/exp_haefnet_test.yml`

## 注意事项
- 预训练权重路径与 Swin/MiT 保持一致（位于 `pretrained/`）。
- 相比原 HARMF 显存略增（多尺度证据 + 决策头）；batch size 可视资源调整。
- 不确定性图分辨率与主输出已对齐（在推理中统一插值）。

## 后续工作（未包含在本次实现）
- MRG（模态可靠性门控）与 Dempster 跨模态组合（参考 `step2_` 与 `step3_`）尚未接入；当前多模态证据在 stage 内先做均值，再进入融合头。

更新时间：2025-09-03
